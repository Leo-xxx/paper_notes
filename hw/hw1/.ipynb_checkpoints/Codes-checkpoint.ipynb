{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./hw1_data/LFW_DATA.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#print data.keys()\n",
    "#[u'database_name', u'query_identity', u'database_identity', u'query_name', u'database_feature', u'query_feature']\n",
    "src = data['database_feature']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 4720)\n",
      "(59, 80, 13113)\n"
     ]
    }
   ],
   "source": [
    "import spams\n",
    "import numpy as np\n",
    "print(src.shape)\n",
    "num = src.shape[0]\n",
    "X = src.reshape([num, 80,59])\n",
    "\n",
    "X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "\n",
    "lambda1 = [10**i for i in range(-6,-3,1)]\n",
    "K = range(100,3200,400)\n",
    "param = { 'K' : 400, # learns a dictionary with 100 elements\n",
    "          'lambda1' : 10**-2, 'numThreads' : -1, 'mode':2,\n",
    "          'iter' : 1000}\n",
    "\n",
    "    \n",
    "print(X.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 80, 13113)\n",
      "(32000, 120)\n",
      "(32000, 13113)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "import spams\n",
    "# print D\n",
    "pathces_num = 80\n",
    "test = data['query_feature']\n",
    "num = test.shape[0]\n",
    "qs = test.reshape([num, 80,59])\n",
    "qs = np.swapaxes(qs,axis1=0,axis2=2)\n",
    "# \n",
    "with open('./dict2.npy','rb') as f:\n",
    "    D_list = np.load(f)\n",
    "    D_list = [np.asfortranarray(D) for D in D_list]\n",
    "def get_codeword(D_list, X,lambda1=0.01):\n",
    "    \n",
    "    param = { 'lambda1' : lambda1, 'lambda2' : 0,'numThreads' : -1, 'mode':2}\n",
    "    buf = []\n",
    "    for i in range(pathces_num):\n",
    "        q = np.asfortranarray(X[:,i,:])\n",
    "        D = D_list[i]\n",
    "        a = spams.lasso(q,D=D,return_reg_path = False,**param)\n",
    "        buf.append(a)\n",
    "    buf = scipy.sparse.vstack(buf)\n",
    "    codeword = np.zeros(buf.shape, dtype=np.bool)\n",
    "    codeword[buf.nonzero()] = True\n",
    "    return codeword\n",
    "\n",
    "#\n",
    "num = src.shape[0]\n",
    "X = src.reshape([num, 80,59])\n",
    "\n",
    "X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "print(X.shape)\n",
    "# \n",
    "q_codeword = get_codeword(D_list, qs)\n",
    "codeword = get_codeword(D_list, X)\n",
    "print(q_codeword.shape)\n",
    "print(codeword.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 32000) (120, 32000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "# 注意要計算and而不是xor(hamming distance)\n",
    "def similarity_sparse_coding(codeword, query):\n",
    "    q = query.ravel()\n",
    "    \n",
    "    distances = []\n",
    "    for x in codeword:\n",
    "#         distances.append(scipy.spatial.distance.hamming(x,query))\n",
    "        distances.append(np.sum(np.logical_and(x,q)))\n",
    "    return reversed(np.argsort(distances))\n",
    "\n",
    "\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "labels = data['database_name'].ravel()\n",
    "\n",
    "queries = np.swapaxes(q_codeword, axis1=0, axis2=1)\n",
    "query_labels = data['query_name'].ravel()\n",
    "print(database.shape, queries.shape)\n",
    "\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "calculate_map(database, labels, queries, query_labels, similarity_sparse_coding)\n",
    "# mAP :  0.13721717999431532\n",
    "# mAP : 0.1581216311119271 with 800\n",
    "print('cost time : ', time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 64000)\n",
      "generating inverted list with 13113 doc, 64000 interested words.\n"
     ]
    }
   ],
   "source": [
    "# inverted index for ranking\n",
    "import threading\n",
    "import numpy as np\n",
    "# input : database[doc_num, word_dim]\n",
    "# output : inverted_list[word_dim] each entry contains a list for docs index.\n",
    "def generate_inverted_list(database, thread_count = 16):\n",
    "    assert len(database.shape) == 2\n",
    "    num, dim = database.shape\n",
    "    print('generating inverted list with %d doc, %d interested words.' % (num, dim))\n",
    "    inv_list = [[] for i in range(dim)]\n",
    "    \n",
    "    for idx,x in enumerate(database):\n",
    "        for i,j in enumerate(x):\n",
    "            if j == True:\n",
    "                inverted_list[i].append(idx)\n",
    "    return inv_list\n",
    "#output : return an idx_list with decresing similarity which depends on occurrence count in inverted list\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "print(database.shape)\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "inv_list = generate_inverted_list(database)\n",
    "t2 = time.time()\n",
    "print('takes : ', t2-t1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 32000) (120, 32000)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def rank_by_inverted_list(database, inverted_list, query):\n",
    "    assert len(query.shape) == 1\n",
    "    assert len(database.shape) == 2\n",
    "    num, _ = database.shape\n",
    "    count = [0] * num\n",
    "    for i,j in enumerate(query):\n",
    "        if j == True:\n",
    "            for idx in inverted_list[i]:\n",
    "                count[idx] += 1\n",
    "    return reversed(np.argsort(count))\n",
    "# print inv_list\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "labels = data['database_name'].ravel()\n",
    "\n",
    "queries = np.swapaxes(q_codeword, axis1=0, axis2=1)\n",
    "query_labels = data['query_name'].ravel()\n",
    "\n",
    "def similarity_with_inverted_list(codeword, query):\n",
    "    return rank_by_inverted_list(codeword, inv_list, query)\n",
    "\n",
    "\n",
    "calculate_map(database, labels, queries, query_labels, similarity_with_inverted_list)\n",
    "# with open('inv_list.pickle','wb') as f:\n",
    "#     pickle.dump(inv_list, f, protocol=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
