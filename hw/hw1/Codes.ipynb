{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./hw1_data/LFW_DATA.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#print data.keys()\n",
    "#[u'database_name', u'query_identity', u'database_identity', u'query_name', u'database_feature', u'query_feature']\n",
    "src = data['database_feature']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\tperson\timagenum\tMale\tAsian\tWhite\tBlack\tBaby\tChild\tYouth\tMiddle Aged\tSenior\tBlack Hair\tBlond Hair\tBrown Hair\tBald\tNo Eyewear\tEyeglasses\tSunglasses\tMustache\tSmiling\tFrowning\tChubby\tBlurry\tHarsh Lighting\tFlash\tSoft Lighting\tOutdoor\tCurly Hair\tWavy Hair\tStraight Hair\tReceding Hairline\tBangs\tSideburns\tFully Visible Forehead\tPartially Visible Forehead\tObstructed Forehead\tBushy Eyebrows\tArched Eyebrows\tNarrow Eyes\tEyes Open\tBig Nose\tPointy Nose\tBig Lips\tMouth Closed\tMouth Slightly Open\tMouth Wide Open\tTeeth Not Visible\tNo Beard\tGoatee\tRound Jaw\tDouble Chin\tWearing Hat\tOval Face\tSquare Face\tRound Face\tColor Photo\tPosed Photo\tAttractive Man\tAttractive Woman\tIndian\tGray Hair\tBags Under Eyes\tHeavy Makeup\tRosy Cheeks\tShiny Skin\tPale Skin\t5 o' Clock Shadow\tStrong Nose-Mouth Lines\tWearing Lipstick\tFlushed Face\tHigh Cheekbones\tBrown Eyes\tWearing Earrings\tWearing Necktie\tWearing Necklace\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./hw1_data/lfw_attributes.txt') as f:\n",
    "    ls = f.readlines()\n",
    "print(ls[1])\n",
    "at = ls[2:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[George W Bush][4] index not in dict. [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530]\n",
      "[Jacques Chirac][6] index not in dict. [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
      "[Jacques Chirac][10] index not in dict. [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
      "miss value  3\n"
     ]
    }
   ],
   "source": [
    "# prepare dict for attributes with name\n",
    "with open('./hw1_data/lfw_attributes.txt') as f:\n",
    "    ls = f.readlines()\n",
    "at = ls[2:]\n",
    "attribute_dict = dict()\n",
    "for l in at:\n",
    "    atts = l.strip().split('\\t')\n",
    "#     print atts\n",
    "    name,idx,male,asian,white = atts[0:5]\n",
    "    if not attribute_dict.has_key(name):\n",
    "        attribute_dict[name] = dict()\n",
    "    attribute_dict[name][int(idx)] = float(male)\n",
    "\n",
    "# missing attributes\n",
    "file_names = data['database_identity'].ravel()\n",
    "miss = 0\n",
    "file_names = data['query_identity'].ravel()\n",
    "for f in file_names:\n",
    "    s = f[0].split('\\\\')[-1].split('.jpg')[0]\n",
    "    idx = int(s.split('_')[-1])\n",
    "    buf = s.replace('_',' ').split(' ')[:-1]\n",
    "#     \n",
    "    name = ''\n",
    "    for b in buf:\n",
    "        name += b\n",
    "        name += ' '\n",
    "    name = name.strip()\n",
    "#         \n",
    "    if not attribute_dict.has_key(name):\n",
    "        print '[%s] not in dict.' % name\n",
    "        miss += 1\n",
    "    else:\n",
    "        if not attribute_dict[name].has_key(idx):\n",
    "            print '[%s][%d] index not in dict.' % (name, idx), attribute_dict[name].keys()\n",
    "            miss+=1\n",
    "#     print name, idx\n",
    "print 'miss value ',miss\n",
    "# print ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 4720)\n",
      "(59, 80, 13113)\n"
     ]
    }
   ],
   "source": [
    "import spams\n",
    "import numpy as np\n",
    "print(src.shape)\n",
    "num = src.shape[0]\n",
    "X = src.reshape([num, 80,59])\n",
    "\n",
    "X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "\n",
    "lambda1 = [10**i for i in range(-6,-3,1)]\n",
    "K = range(100,3200,400)\n",
    "param = { 'K' : 400, # learns a dictionary with 100 elements\n",
    "          'lambda1' : 10**-2, 'numThreads' : -1, 'mode':2,\n",
    "          'iter' : 1000}\n",
    "\n",
    "    \n",
    "print(X.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (59, 120)\n",
      "d (59, 60)\n",
      "w (60, 120)\n",
      "x (59, 13113)\n",
      "d (59, 60)\n",
      "w (60, 13113)\n",
      "(60,)\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False  True  True\n",
      " False False False  True False False False False False False False False\n",
      " False  True  True  True False False  True False  True False  True  True]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import spams\n",
    "import numpy as np\n",
    "import scipy\n",
    "def train_SC(database, param, out_file='./dict.npy'):\n",
    "\n",
    "\n",
    "    num = database.shape[0]\n",
    "    X = database.reshape([num, 80,59])\n",
    "    X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "\n",
    "    D_list = []\n",
    "    pathces_num = X.shape[1]\n",
    "#     for i in range(pathces_num):\n",
    "    for i in range(1):\n",
    "        x = np.asfortranarray(X[:,i,:])\n",
    "        D = spams.trainDL(x,**param)\n",
    "        D_list.append(D)\n",
    "#     with open(out_file,'wb') as f:\n",
    "#         np.save(f,D_list)\n",
    "#     print('Done')\n",
    "#     with open(out_file,'rb') as f:\n",
    "#         data = np.load(f)\n",
    "#     print(data.shape)\n",
    "    return D_list\n",
    "def sparse_coding(q_features, db_features, param):\n",
    "    qs = q_features.reshape([len(q_features), 80,59])\n",
    "    qs = np.swapaxes(qs,axis1=0,axis2=2)\n",
    "    X = db_features.reshape([len(db_features), 80,59])\n",
    "    X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "    \n",
    "    D_list = train_SC(db_features, param)\n",
    "    q_codeword = get_codeword(D_list, qs)\n",
    "    db_codeword = get_codeword(D_list, X)\n",
    "    \n",
    "    return q_codeword, db_codeword\n",
    "def get_codeword(D_list, X,lambda1=0.01):\n",
    "    n = X.shape[-1]\n",
    "    W = np.ones([60,n],dtype=float)\n",
    "    W[:30] = float('inf')\n",
    "    param = { 'lambda1' : lambda1,'numThreads' : -1, 'mode':2, 'W':np.asfortranarray(W)}\n",
    "    buf = []\n",
    "    pathces_num = len(D_list)\n",
    "    for i in range(pathces_num):\n",
    "        q = np.asfortranarray(X[:,i,:])\n",
    "        D = D_list[i]\n",
    "        print 'x', q.shape\n",
    "        print 'd', D.shape\n",
    "        print 'w', W.shape\n",
    "        \n",
    "        a = spams.lassoWeighted(q,D=D,**param)\n",
    "        buf.append(a)\n",
    "    buf = scipy.sparse.vstack(buf)\n",
    "    codeword = np.zeros(buf.shape, dtype=np.bool)\n",
    "    codeword[buf.nonzero()] = True\n",
    "    \n",
    "    \n",
    "    codeword = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "    \n",
    "    return codeword\n",
    "database = data['database_feature']\n",
    "queries = data['query_feature']\n",
    "labels = data['database_name'].ravel()\n",
    "query_labels = data['query_name'].ravel()\n",
    "\n",
    "#part 1: l2_distance and calculate_map\n",
    "# mAP = calculate_map(database, labels, queries, query_labels, l2_distance)\n",
    "# print(mAP)\n",
    "\n",
    "#part 2: sparse_coding\n",
    "pos = np.asfortranarray([3]*200)\n",
    "param = { 'K' : 60,\n",
    "                  'lambda1' : 0.01, 'numThreads' : -1, 'mode':2,\n",
    "                  'iter' : 3}\n",
    "        \n",
    "q_sparse, db_sparse = sparse_coding(queries, database, param) #build sparse dict and lookup using spams library\n",
    "# sparse_map = calculate_map(db_sparse, labels, q_sparse, query_labels, similarity_sparse_coding)# results_sparse = distance(q_sparse, db_sparse) #you can use l2_distance in part1 or try any distance metric, like cos, l1 \n",
    "\n",
    "# sparse_coding(queries, database, param)\n",
    "q = q_sparse[0,:]\n",
    "print q.shape\n",
    "print q\n",
    "print 'Done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 80, 13113)\n",
      "(32000, 120)\n",
      "(32000, 13113)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.spatial\n",
    "import numpy as np\n",
    "import spams\n",
    "# print D\n",
    "pathces_num = 80\n",
    "test = data['query_feature']\n",
    "num = test.shape[0]\n",
    "qs = test.reshape([num, 80,59])\n",
    "qs = np.swapaxes(qs,axis1=0,axis2=2)\n",
    "# \n",
    "with open('./dict2.npy','rb') as f:\n",
    "    D_list = np.load(f)\n",
    "    D_list = [np.asfortranarray(D) for D in D_list]\n",
    "def get_codeword(D_list, X,lambda1=0.01):\n",
    "    \n",
    "    param = { 'lambda1' : lambda1, 'lambda2' : 0,'numThreads' : -1, 'mode':2}\n",
    "    buf = []\n",
    "    for i in range(pathces_num):\n",
    "        q = np.asfortranarray(X[:,i,:])\n",
    "        D = D_list[i]\n",
    "        a = spams.lasso(q,D=D,return_reg_path = False,**param)\n",
    "        buf.append(a)\n",
    "    buf = scipy.sparse.vstack(buf)\n",
    "    codeword = np.zeros(buf.shape, dtype=np.bool)\n",
    "    codeword[buf.nonzero()] = True\n",
    "    return codeword\n",
    "\n",
    "#\n",
    "num = src.shape[0]\n",
    "X = src.reshape([num, 80,59])\n",
    "\n",
    "X = np.swapaxes(X,axis1=0,axis2=2)\n",
    "print(X.shape)\n",
    "# \n",
    "q_codeword = get_codeword(D_list, qs)\n",
    "codeword = get_codeword(D_list, X)\n",
    "print(q_codeword.shape)\n",
    "print(codeword.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 32000) (120, 32000)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mAp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e15e09fd5eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mcalculate_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_sparse_coding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# mAP :  0.13721717999431532\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# mAP : 0.1581216311119271 with 800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/paper_notes/hw/hw1/calculate_map.py\u001b[0m in \u001b[0;36mcalculate_map\u001b[0;34m(database, labels, queries, query_labels, similarity_func)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mAPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         print i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mAp' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "# 注意要計算and而不是xor(hamming distance)\n",
    "def similarity_sparse_coding(codeword, query):\n",
    "    q = query.ravel()\n",
    "    \n",
    "    distances = []\n",
    "    for x in codeword:\n",
    "#         distances.append(scipy.spatial.distance.hamming(x,query))\n",
    "        distances.append(np.sum(np.logical_and(x,q)))\n",
    "    return reversed(np.argsort(distances))\n",
    "\n",
    "\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "labels = data['database_name'].ravel()\n",
    "\n",
    "queries = np.swapaxes(q_codeword, axis1=0, axis2=1)\n",
    "query_labels = data['query_name'].ravel()\n",
    "print(database.shape, queries.shape)\n",
    "\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "calculate_map(database, labels, queries, query_labels, similarity_sparse_coding)\n",
    "# mAP :  0.13721717999431532\n",
    "# mAP : 0.1581216311119271 with 800\n",
    "print('cost time : ', time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 64000)\n",
      "generating inverted list with 13113 doc, 64000 interested words.\n"
     ]
    }
   ],
   "source": [
    "# inverted index for ranking\n",
    "import threading\n",
    "import numpy as np\n",
    "# input : database[doc_num, word_dim]\n",
    "# output : inverted_list[word_dim] each entry contains a list for docs index.\n",
    "def generate_inverted_list(database, thread_count = 16):\n",
    "    assert len(database.shape) == 2\n",
    "    num, dim = database.shape\n",
    "    print('generating inverted list with %d doc, %d interested words.' % (num, dim))\n",
    "    inv_list = [[] for i in range(dim)]\n",
    "    \n",
    "    for idx,x in enumerate(database):\n",
    "        for i,j in enumerate(x):\n",
    "            if j == True:\n",
    "                inverted_list[i].append(idx)\n",
    "    return inv_list\n",
    "#output : return an idx_list with decresing similarity which depends on occurrence count in inverted list\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "print(database.shape)\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "inv_list = generate_inverted_list(database)\n",
    "t2 = time.time()\n",
    "print('takes : ', t2-t1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13113, 32000) (120, 32000)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def rank_by_inverted_list(database, inverted_list, query):\n",
    "    assert len(query.shape) == 1\n",
    "    assert len(database.shape) == 2\n",
    "    num, _ = database.shape\n",
    "    count = [0] * num\n",
    "    for i,j in enumerate(query):\n",
    "        if j == True:\n",
    "            for idx in inverted_list[i]:\n",
    "                count[idx] += 1\n",
    "    return reversed(np.argsort(count))\n",
    "# print inv_list\n",
    "database = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "labels = data['database_name'].ravel()\n",
    "\n",
    "queries = np.swapaxes(q_codeword, axis1=0, axis2=1)\n",
    "query_labels = data['query_name'].ravel()\n",
    "\n",
    "def similarity_with_inverted_list(codeword, query):\n",
    "    return rank_by_inverted_list(codeword, inv_list, query)\n",
    "\n",
    "\n",
    "calculate_map(database, labels, queries, query_labels, similarity_with_inverted_list)\n",
    "# with open('inv_list.pickle','wb') as f:\n",
    "#     pickle.dump(inv_list, f, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "from l2_distance import l2_distance #l2_distance.py\n",
    "from sparse_coding import sparse_coding,similarity_sparse_coding #sparse_coding.py\n",
    "from calculate_map import calculate_map #calculate_map.py\n",
    "import pickle\n",
    "lfw_path = './hw1_data/LFW_DATA.pickle'\n",
    "with open(lfw_path, 'rb') as f:\n",
    "    lfw = pickle.load(f)\n",
    "database = lfw['database_feature']\n",
    "queries = lfw['query_feature']\n",
    "labels = lfw['database_name'].ravel()\n",
    "query_labels = lfw['query_name'].ravel()\n",
    "\n",
    "#part 1: l2_distance and calculate_map\n",
    "# mAP = calculate_map(database, labels, queries, query_labels, l2_distance)\n",
    "# print(mAP)\n",
    "\n",
    "#part 2: sparse_coding\n",
    "param = { 'K' : 400,\n",
    "                  'lambda1' : 0.01, 'numThreads' : -1, 'mode':2,\n",
    "                  'iter' : -10}\n",
    "        \n",
    "q_sparse, db_sparse = sparse_coding(lfw['query_feature'], lfw['database_feature'], param) #build sparse dict and lookup using spams library\n",
    "sparse_map = calculate_map(db_sparse, labels, q_sparse, query_labels, similarity_sparse_coding)# results_sparse = distance(q_sparse, db_sparse) #you can use l2_distance in part1 or try any distance metric, like cos, l1 \n",
    "print(sparse_map)\n",
    "#part 3\n",
    "lambda1 = [10**i for i in range(-6,-3,1)]\n",
    "K = range(100,3200,400)\n",
    "iter_ = -10\n",
    "for k in K:\n",
    "    for l1 in lambda1:\n",
    "        \n",
    "\n",
    "        param = { 'K' : k,\n",
    "                  'lambda1' : l1, 'numThreads' : -1, 'mode':2,\n",
    "                  'iter' : iter_}\n",
    "        q_sparse, db_sparse = sparse_coding(lfw['query_feature'], lfw['database_feature'], param) #build sparse dict and lookup using spams library\n",
    "        sparse_map = calculate_map(db_sparse, labels, q_sparse, query_labels, similarity_sparse_coding)# results_sparse = distance(q_sparse, db_sparse) #you can use l2_distance in part1 or try any distance metric, like cos, l1 \n",
    "\n",
    "        print(k,l1, sparse_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14895016188476712\n"
     ]
    }
   ],
   "source": [
    "sparse_map = calculate_map(db_sparse, labels, q_sparse, query_labels, similarity_sparse_coding)# results_sparse = distance(q_sparse, db_sparse) #you can use l2_distance in part1 or try any distance metric, like cos, l1 \n",
    "print(sparse_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8452432df8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_coding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_SC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0msparse_coding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_D_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./dict200.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git_repo/paper_notes/hw/hw1/sparse_coding.py\u001b[0m in \u001b[0;36mtrain_SC\u001b[0;34m(database, param)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathces_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfortranarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mD_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mD_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spams.pyc\u001b[0m in \u001b[0;36mtrainDL\u001b[0;34m(X, return_model, model, D, numThreads, batchsize, K, lambda1, lambda2, iter, t0, mode, posAlpha, posD, expand, modeD, whiten, clean, verbose, gamma1, gamma2, rho, iter_updateD, stochastic_deprecated, modeParam, batch, log_deprecated, logName)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[0mlambda3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m     \u001b[0mregul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1983\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m__allTrainDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumThreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposAlpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodeD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_updateD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstochastic_deprecated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodeParam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_deprecated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m def structTrainDL(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spams.pyc\u001b[0m in \u001b[0;36m__allTrainDL\u001b[0;34m(X, return_model, model, in_memory, D, graph, tree, numThreads, tol, fixed_step, ista, batchsize, K, lambda1, lambda2, lambda3, iter, t0, mode, regul, posAlpha, posD, expand, modeD, whiten, clean, verbose, gamma1, gamma2, rho, iter_updateD, stochastic_deprecated, modeParam, batch, log_deprecated, logName)\u001b[0m\n\u001b[1;32m   1829\u001b[0m         \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposAlpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m         \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodeD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_updateD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m         stochastic_deprecated,modeParam,batch,log_deprecated,logName)\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spams_wrap.pyc\u001b[0m in \u001b[0;36malltrainDL\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0malltrainDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mreturn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0mm_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meta_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroups_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mown_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVector\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN_own_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mfixed_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mista\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mlambda2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mlambda3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint_type\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mname_regul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mposAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mposD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint_type_D\u001b[0m \u001b[0mmodeD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mwhiten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mgamma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble\u001b[0m \u001b[0mgamma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0miter_updateD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m \u001b[0mmodeParam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogName\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mMatrix\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_spams_wrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malltrainDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0marchetypalAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train for attributed\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sparse_coding\n",
    "\n",
    "lfw_path = './hw1_data/LFW_DATA.pickle'\n",
    "with open(lfw_path, 'rb') as f:\n",
    "    lfw = pickle.load(f)\n",
    "database = lfw['database_feature']\n",
    "\n",
    "param = { 'K' : 200,\n",
    "              'lambda1' : 0.01, 'numThreads' : -1, 'mode':2,\n",
    "              'iter' : -10}\n",
    "\n",
    "\n",
    "D_list = sparse_coding.train_SC(database, param)\n",
    "sparse_coding.save_D_list(D_list, out_file='./dict200.npy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load for attributed\n",
    "import pickle\n",
    "import numpy as np\n",
    "lfw_path = './hw1_data/LFW_DATA.pickle'\n",
    "with open(lfw_path, 'rb') as f:\n",
    "    lfw = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qax (120, 1)\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './dict800.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-0dd3f2ff69e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mqaX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attribute_martix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_file_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'qax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mqaX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mD_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_D_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dict800.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-0dd3f2ff69e2>\u001b[0m in \u001b[0;36mload_D_list\u001b[0;34m(in_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_D_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./dict200.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './dict800.npy'"
     ]
    }
   ],
   "source": [
    "import spams\n",
    "import scipy\n",
    "\n",
    "def load_D_list(in_file='./dict200.npy'):\n",
    "    with open(in_file,'rb') as f:\n",
    "        data = np.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_name_idx_from_filename(s):\n",
    "    s = s[0].split('\\\\')[-1].split('.jpg')[0]\n",
    "    idx = int(s.split('_')[-1])\n",
    "    buf = s.replace('_',' ').split(' ')[:-1]\n",
    "    \n",
    "    name = ''\n",
    "    for b in buf:\n",
    "        name += b\n",
    "        name += ' '\n",
    "    name = name.strip()\n",
    "    return name, idx\n",
    "\n",
    "def get_attribute_martix(features, identities, attribute_dict):\n",
    "    X = np.zeros([ features.shape[0], 1])\n",
    "    for i,f in enumerate(identities):\n",
    "        name, idx = extract_name_idx_from_filename(f)\n",
    "        value = 0\n",
    "        if not attribute_dict.has_key(name):\n",
    "            value = 0\n",
    "        elif not attribute_dict[name].has_key(idx):\n",
    "            value = 0\n",
    "        else:\n",
    "            value = attribute_dict[name][idx]\n",
    "        X[i,0] = value\n",
    "    return X\n",
    "\n",
    "def get_weight_matrix(att, p=200, weight=float('inf'), var=120.):\n",
    "#     W:  double p x n matrix   (weights)\n",
    "    n = att.shape[0]\n",
    "    W = np.ones([p,n])\n",
    "    \n",
    "#     ASC-D\n",
    "#     for i,at in enumerate(att):\n",
    "#         if at >= 0: # contain missing value\n",
    "#             W[:p/2,i] = weight\n",
    "#         else:\n",
    "#             W[p/2:,i] = weight\n",
    "\n",
    "#     ASC-W\n",
    "    A = np.ones([p,])\n",
    "    A[p/2:] = -1\n",
    "    for i,at in enumerate(att):\n",
    "        fa = np.repeat(at,p)\n",
    "        assert fa.shape == (p, )\n",
    "        W[:,i] = np.exp(np.abs(fa-A)/var)\n",
    "    return np.asfortranarray(W)\n",
    "\n",
    "def load_attribute_dict(path='./hw1_data/lfw_attributes.txt'):\n",
    "    # prepare dict for attributes with name\n",
    "    with open(path) as f:\n",
    "        ls = f.readlines()\n",
    "    at = ls[2:]\n",
    "    attribute_dict = dict()\n",
    "    for l in at:\n",
    "        atts = l.strip().split('\\t')\n",
    "    #     print atts\n",
    "        name,idx,male,asian,white = atts[0:5]\n",
    "        if not attribute_dict.has_key(name):\n",
    "            attribute_dict[name] = dict()\n",
    "        attribute_dict[name][int(idx)] = float(white)\n",
    "    return attribute_dict\n",
    "\n",
    "def get_codeword(D_list, X, aX, lambda1=0.01, pathces_num=80):\n",
    "    \n",
    "    param = { 'lambda1' : lambda1, 'numThreads' : -1, 'mode':2}\n",
    "    buf = []\n",
    "    p = D_list.shape[-1]\n",
    "    W = get_weight_matrix(aX,p)\n",
    "    for i in range(pathces_num):\n",
    "        q = np.asfortranarray(X[:,i,:])\n",
    "        D = D_list[i]\n",
    "        a = spams.lassoWeighted(q,D=np.asfortranarray(D),W=W,**param)\n",
    "        buf.append(a)\n",
    "    buf = scipy.sparse.vstack(buf)\n",
    "    codeword = np.zeros(buf.shape, dtype=np.bool)\n",
    "    codeword[buf.nonzero()] = True\n",
    "    codeword = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "    return codeword\n",
    "def get_codeword2(D_list, X, aX, lambda1=0.01, pathces_num=80):\n",
    "    \n",
    "    param = { 'lambda1' : lambda1, 'numThreads' : -1, 'mode':2}\n",
    "    buf = []\n",
    "    for i in range(pathces_num):\n",
    "        q = np.asfortranarray(X[:,i,:])\n",
    "        D = D_list[i]\n",
    "        a = spams.lasso(q,D=np.asfortranarray(D),**param)\n",
    "        buf.append(a)\n",
    "    buf = scipy.sparse.vstack(buf)\n",
    "    codeword = np.zeros(buf.shape, dtype=np.bool)\n",
    "    codeword[buf.nonzero()] = True\n",
    "    codeword = np.swapaxes(codeword, axis1=0, axis2=1)\n",
    "    return codeword\n",
    "\n",
    "database = lfw['database_feature']\n",
    "file_names = lfw['database_identity'].ravel()\n",
    "q_database = lfw['query_feature']\n",
    "q_file_names = lfw['query_identity'].ravel()\n",
    "\n",
    "attribute_dict = load_attribute_dict(path='./hw1_data/lfw_attributes.txt')\n",
    "\n",
    "aX = get_attribute_martix(database, file_names, attribute_dict)\n",
    "qaX = get_attribute_martix(q_database, q_file_names, attribute_dict)\n",
    "print 'qax',qaX.shape\n",
    "D_list = load_D_list('./dict800.npy')\n",
    "\n",
    "p = D_list.shape[-1]\n",
    "print p\n",
    "query = lfw['query_feature']\n",
    "query = query.reshape([-1,80,59])\n",
    "query = np.swapaxes(query, 0, 2)\n",
    "train_X = database.reshape([-1,80,59])\n",
    "train_X = np.swapaxes(train_X, 0, 2)\n",
    "print query.shape\n",
    "db_sparse = get_codeword2(D_list, train_X, aX)\n",
    "print 'db done'\n",
    "q_sparse = get_codeword2(D_list, query, qaX)\n",
    "W = get_weight_matrix(qaX)\n",
    "# print q_sparse.shape\n",
    "# print W[90:110,0],q_sparse[0,:]\n",
    "\n",
    "print db_sparse.shape, q_sparse.shape\n",
    "print 'shape done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15933643322936533\n",
      "0.158974217281 ASC-W white 800\n",
      "0.157690878436 ASC-W white 400\n",
      "0.153723990337 ASC-W white\n",
      "0.138095560915 ASC-D male\n",
      "0.153241285184 ASC-W male\n",
      "0.152328678016 SC\n",
      "0.158121631112 SC 800\n"
     ]
    }
   ],
   "source": [
    "from sparse_coding import sparse_coding,similarity_sparse_coding #sparse_coding.py\n",
    "from calculate_map import calculate_map #calculate_map.py\n",
    "labels = lfw['database_name'].ravel()\n",
    "query_labels = lfw['query_name'].ravel()\n",
    "\n",
    "sparse_map = calculate_map(db_sparse, labels, q_sparse, query_labels, similarity_sparse_coding)\n",
    "print sparse_map\n",
    "print 0.1589742172809806,'ASC-W white 800'\n",
    "print 0.15933643322936533,'ASC-W white 400'\n",
    "print 0.1537239903366804,'ASC-W white'\n",
    "print 0.1380955609153339,'ASC-D male'\n",
    "print 0.1532412851844244,'ASC-W male'\n",
    "print 0.1523286780158036,'SC'\n",
    "print 0.1581216311119271,'SC 400'\n",
    "print 0.157690878436,'SC 800'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f583411f4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "a = np.array([0.1537239903366804,0.15933643322936533,0.1589742172809806])\n",
    "b = np.array([0.1523286780158036,0.1581216311119271,0.157690878436])\n",
    "c = np.array([200,400,800])\n",
    "\n",
    "plt.plot(c,a,'b-')\n",
    "plt.plot(c,b,'r-')\n",
    "\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('mAP')\n",
    "plt.show()\n",
    "plt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
