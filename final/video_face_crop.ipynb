{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from time import time\n",
    "from os.path import join\n",
    "import random, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CASC_PATH = join('./','haarcascade_files','haarcascade_frontalface_default.xml')\n",
    "cascade_classifier = cv2.CascadeClassifier(CASC_PATH)\n",
    "    \n",
    "\n",
    "def detect_face(image, return_max_area_face=True):\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = cv2.imdecode(image, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is we don't found an image\n",
    "    if not len(faces) > 0:\n",
    "        return []\n",
    "    if return_max_area_face:\n",
    "        max_area_face = faces[0]\n",
    "        for face in faces:\n",
    "            if face[2] * face[3] > max_area_face[2] * max_area_face[3]:\n",
    "                max_area_face = face\n",
    "        faces = [max_area_face, ]\n",
    "\n",
    "    return faces\n",
    "\n",
    "def bounding_face(frame, faces, factor, constraint=None):\n",
    "    bounding_box_list = []\n",
    "    \n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        factor = 2.\n",
    "        offset = (factor-1)/2.\n",
    "        rect = [x-offset*w, y-offset*h, w*factor, h*factor]\n",
    "        for i,a in enumerate(rect):\n",
    "            rect[i] = int(a)\n",
    "        rect = tuple(rect)\n",
    "\n",
    "\n",
    "\n",
    "        x,y = rect[:2]\n",
    "        x2 = x + rect[2]\n",
    "        y2 = y + rect[3]\n",
    "        box = (int(x), int(y)), (int(x2), int(y2))\n",
    "        box = shift_box(frame, box)\n",
    "        if box:\n",
    "        \n",
    "            if constraint:\n",
    "                if constraint(box):\n",
    "                    bounding_box_list.append(box)\n",
    "            else:\n",
    "                bounding_box_list.append(box)\n",
    "    return bounding_box_list\n",
    "def bounding_face_fixed_size(frame, faces, fixed_size, constraint=None):\n",
    "    bounding_box_list = []\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        offset_x = (fixed_size-w)/2.\n",
    "        offset_y = (fixed_size-h)/2.\n",
    "        rect = [x-offset_x, y-offset_y, fixed_size, fixed_size]\n",
    "        for i,a in enumerate(rect):\n",
    "            rect[i] = int(a)\n",
    "        rect = tuple(rect)\n",
    "\n",
    "        \n",
    "\n",
    "        x,y = rect[:2]\n",
    "        x2 = x + rect[2]\n",
    "        y2 = y + rect[3]\n",
    "        box = (int(x), int(y)), (int(x2), int(y2))\n",
    "        box = shift_box(frame, box)\n",
    "        if box:\n",
    "            if constraint:\n",
    "                if constraint(box):\n",
    "                    bounding_box_list.append(box)\n",
    "            else:\n",
    "                bounding_box_list.append(box)\n",
    "    return bounding_box_list\n",
    "# handle the situation that box boundary reachs the boundary of frame. ex, y<0\n",
    "def shift_box(frame, box):\n",
    "    h ,w ,dep = frame.shape\n",
    "    (x, y), (x2, y2) = box\n",
    "    if y < 0:\n",
    "        y2 -= y\n",
    "        y = 0\n",
    "    if x < 0:\n",
    "        x2 -= x\n",
    "        x = 0\n",
    "    if x2 > w:\n",
    "        x -= x2-w\n",
    "        x2 = w\n",
    "    if y2 > h:\n",
    "        y -= y2-h\n",
    "        y2 = h\n",
    "    if x < 0 or y < 0 or x2 > w or y2 > h:\n",
    "        return False\n",
    "    else:\n",
    "        box = (int(x), int(y)), (int(x2), int(y2))\n",
    "        return box\n",
    "def draw_bounding_box(frame, bounding_box_list):\n",
    "    for box in bounding_box_list:\n",
    "        (x, y), (x2, y2) = box\n",
    "        cv2.rectangle(frame, (x, y), (x2, y2) , color=(255,255,255), thickness=5)\n",
    "    return frame\n",
    "def crop_bounding_box(frame, bounding_box_list):\n",
    "    frame_list = []\n",
    "    for box in bounding_box_list:\n",
    "        (x, y), (x2, y2) = box\n",
    "        f = frame[y:y2,x:x2,:]\n",
    "        frame_list.append(f)\n",
    "    return frame_list\n",
    "\n",
    "def demo(video_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=None, skip_beg_frame=0):\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    for i in range(skip_beg_frame):\n",
    "        ret, frame = cap.read()\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        faces = detect_face(frame, return_max_area_face)\n",
    "        if factor:\n",
    "            bounding_box_list = bounding_face(frame, faces, factor, constraint)\n",
    "        elif fixed_size:\n",
    "            bounding_box_list = bounding_face_fixed_size(frame, faces, fixed_size, constraint)\n",
    "        else:\n",
    "            print 'error'\n",
    "            break\n",
    "        frame = draw_bounding_box(frame, bounding_box_list)\n",
    "        cv2.imshow('frame',frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('k'):\n",
    "            for i in range(random.randint(0,200)):\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=None, skip_beg_frame=0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    with tqdm(total=frame_length) as pbar:\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(skip_beg_frame):\n",
    "            ret, frame = cap.read()\n",
    "            pbar.update(1)\n",
    "        existed_jpgs = [f for f in os.listdir(ouptut_path) if f.endswith('.jpg')]\n",
    "        idx = len(existed_jpgs)\n",
    "        print 'start from idx : %d' % idx\n",
    "        while(cap.isOpened()):\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            pbar.update(1)\n",
    "            faces = detect_face(frame, return_max_area_face)\n",
    "            if factor:\n",
    "                bounding_box_list = bounding_face(frame, faces, factor, constraint)\n",
    "            elif fixed_size:\n",
    "                bounding_box_list = bounding_face_fixed_size(frame, faces, fixed_size, constraint)\n",
    "            else:\n",
    "                print 'error'\n",
    "                break\n",
    "            frame_list = crop_bounding_box(frame, bounding_box_list)\n",
    "            for frame in frame_list:\n",
    "                out_path = join(ouptut_path,'%d.jpg' % idx)\n",
    "                idx += 1\n",
    "                write_ret = cv2.imwrite(out_path,frame)\n",
    "                if not write_ret:\n",
    "                    write_ret = cv2.imwrite(out_path,frame)\n",
    "                    print frame\n",
    "                    print out_path                    \n",
    "    #             skip 10 frame\n",
    "                for i in range(10):\n",
    "                    ret, frame = cap.read()\n",
    "                    pbar.update(1)\n",
    "    print 'Cropping : Done'\n",
    "    \n",
    "def demo_and_crop(ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=None, skip_beg_frame=0):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    frame_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    existed_jpgs = [f for f in os.listdir(ouptut_path) if f.endswith('.jpg')]\n",
    "    idx = len(existed_jpgs)\n",
    "    print 'start from idx : %d' % idx\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        faces = detect_face(frame, return_max_area_face)\n",
    "        if factor:\n",
    "            bounding_box_list = bounding_face(frame, faces, factor, constraint)\n",
    "        elif fixed_size:\n",
    "            bounding_box_list = bounding_face_fixed_size(frame, faces, fixed_size, constraint)\n",
    "        else:\n",
    "            print 'error'\n",
    "            break\n",
    "        b_frame = draw_bounding_box(frame, bounding_box_list)\n",
    "        cv2.imshow('frame',b_frame)\n",
    "\n",
    "        frame_list = crop_bounding_box(frame, bounding_box_list)\n",
    "        for frame in frame_list:\n",
    "            out_path = join(ouptut_path,'%d.jpg' % idx)\n",
    "            idx += 1\n",
    "            write_ret = cv2.imwrite(out_path,frame)\n",
    "            if not write_ret:\n",
    "                write_ret = cv2.imwrite(out_path,frame)\n",
    "                \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print 'Done'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# demo crop\n",
    "skip_beg_frame = 0\n",
    "\n",
    "ouptut_path = join('./','buf_data','lin')\n",
    "\n",
    "fixed_size = 450\n",
    "factor = None\n",
    "demo_and_crop(ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蔡英文520就職典禮\n",
    "def constrain_1(box):\n",
    "    (x, y), (x2, y2) = box\n",
    "    return x > 450 and x2 < 1000\n",
    "skip_beg_frame = 200\n",
    "video_path = join('./','buf_data','520_TW_president_speech.mp4')\n",
    "\n",
    "ouptut_path = join('./','buf_data','president')\n",
    "\n",
    "fixed_size = 320\n",
    "factor = None\n",
    "\n",
    "demo(video_path, constraint=constrain_1, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "# crop_video(video_path, ouptut_path, constraint=constrain_1, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蔡英文CSIS演說\n",
    "video_path = join('./','buf_data','TW_president_CSIS.mp4')\n",
    "skip_beg_frame = 1000\n",
    "ouptut_path = join('./','buf_data','president')\n",
    "fixed_size = 320\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蔡英文 president_2016\n",
    "video_path = join('./','buf_data','president_2016.mp4')\n",
    "skip_beg_frame = 7000\n",
    "fixed_size = 320\n",
    "factor = None\n",
    "ouptut_path = join('./','buf_data','president')\n",
    "\n",
    "demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "# crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3778 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3784it [02:07, 29.64it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 蔡英文 TV show\n",
    "video_path = join('./','buf_data','president_TV.mp4')\n",
    "skip_beg_frame = 000\n",
    "fixed_size = 600\n",
    "factor = None\n",
    "ouptut_path = join('./','buf_data','president')\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 202/36320 [00:00<01:47, 336.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 36317/36320 [12:01<00:00, 50.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 蔡英文 speech\n",
    "video_path = join('./','buf_data','president_speech.mp4')\n",
    "skip_beg_frame = 200\n",
    "fixed_size = 350\n",
    "factor = None\n",
    "ouptut_path = join('./','buf_data','president')\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/73216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73220it [50:37, 24.10it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 館長\n",
    "video_path = join('./','buf_data','fit_coach1.mp4')\n",
    "skip_beg_frame = 0 \n",
    "fixed_size = 500\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','fit_coach')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 館長2\n",
    "video_path = join('./','buf_data','fit_coach2.mp4')\n",
    "skip_beg_frame = 0 \n",
    "fixed_size = 460\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','fit_coach')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 487/55070 [00:02<03:34, 254.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 15628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55070/55070 [27:43<00:00,  4.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 館長3\n",
    "video_path = join('./','buf_data','fit_coach3.mp4')\n",
    "skip_beg_frame = 500\n",
    "fixed_size = 720\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','fit_coach')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 95/9970 [00:00<00:23, 422.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9972it [04:09, 39.90it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annie 1\n",
    "video_path = join('./','buf_data','annie_1.mp4')\n",
    "skip_beg_frame = 100\n",
    "fixed_size = 450\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','annie')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 102/6337 [00:00<00:25, 246.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6337/6337 [01:31<00:00, 69.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annie 2\n",
    "video_path = join('./','buf_data','annie_2.mp4')\n",
    "skip_beg_frame = 100\n",
    "fixed_size = 450\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','annie')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 91/7019 [00:00<00:16, 424.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7019/7019 [01:53<00:00, 62.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annie 3\n",
    "video_path = join('./','buf_data','annie_3.mp4')\n",
    "skip_beg_frame = 100\n",
    "fixed_size = 450\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','annie')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 102/8149 [00:00<00:30, 263.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from idx : 1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8149/8149 [02:01<00:00, 67.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping : Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annie 4\n",
    "video_path = join('./','buf_data','annie_4.mp4')\n",
    "skip_beg_frame = 100\n",
    "fixed_size = 450\n",
    "factor = None\n",
    "\n",
    "# demo(video_path, constraint=None, return_max_area_face=True, factor=factor, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "ouptut_path = join('./','buf_data','annie')\n",
    "crop_video(video_path, ouptut_path, constraint=None, return_max_area_face=True, factor=None, fixed_size=fixed_size, skip_beg_frame=skip_beg_frame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
