{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "22002.618181818183 17298242.49966942\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from time import time\n",
    "from os.path import join\n",
    "import random\n",
    "# from PIL import Image\n",
    "# from IPython.display import display\n",
    "# import matplotlib.pyplot as plt\n",
    "buf = []\n",
    "def showX(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "#     int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "#     if channel_first:\n",
    "#         int_X = np.moveaxis(int_X.reshape(-1,3,imageSize,imageSize), 1, 3)\n",
    "#     else:\n",
    "#         int_X = int_X.reshape(-1,imageSize,imageSize, 3)\n",
    "#     int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
    "#     \n",
    "#     im = im.resize( (loadSize, loadSize), Image.BILINEAR )\n",
    "    display(Image.fromarray(int_X))\n",
    "    \n",
    "def detect_face(image, return_max_area_face=True):\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = cv2.imdecode(image, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is we don't found an image\n",
    "    if not len(faces) > 0:\n",
    "        return []\n",
    "    if return_max_area_face:\n",
    "        max_area_face = faces[0]\n",
    "        for face in faces:\n",
    "            if face[2] * face[3] > max_area_face[2] * max_area_face[3]:\n",
    "                max_area_face = face\n",
    "        faces = [max_area_face, ]\n",
    "\n",
    "    return faces\n",
    "def bounding_face(frame, faces, factor, dim_constraint=0):\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        factor = 2.\n",
    "        offset = (factor-1)/2.\n",
    "        rect = [x-offset*w, y-offset*h, w*factor, h*factor]\n",
    "        for i,a in enumerate(rect):\n",
    "            rect[i] = int(a)\n",
    "        rect = tuple(rect)\n",
    "\n",
    "\n",
    "\n",
    "        x,y = rect[:2]\n",
    "        x2 = x + rect[2]\n",
    "        y2 = y + rect[3]\n",
    "    #         for 蔡英文\n",
    "#         print x,x2\n",
    "        if x > 450 and x2 < 1000:\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x2), int(y2)), color=(255,255,255), thickness=5)\n",
    "            a = w*h\n",
    "            buf.append(a)\n",
    "            print w,h\n",
    "    return frame\n",
    "def bounding_face_keep(frame, faces, box_constraint):\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        offset_x = (box_constraint-w)/2.\n",
    "        offset_y = (box_constraint-h)/2.\n",
    "        rect = [x-offset_x, y-offset_y, box_constraint, box_constraint]\n",
    "        for i,a in enumerate(rect):\n",
    "            rect[i] = int(a)\n",
    "        rect = tuple(rect)\n",
    "\n",
    "        \n",
    "\n",
    "        x,y = rect[:2]\n",
    "        x2 = x + rect[2]\n",
    "        y2 = y + rect[3]\n",
    "    #         for 蔡英文\n",
    "        \n",
    "        if x > 450 and x2 < 1000:\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x2), int(y2)), color=(255,255,255), thickness=5)\n",
    "            a = w*h\n",
    "            buf.append(a)\n",
    "    return frame\n",
    "\n",
    "\n",
    "    \n",
    "CASC_PATH = join('./','haarcascade_files','haarcascade_frontalface_default.xml')\n",
    "cascade_classifier = cv2.CascadeClassifier(CASC_PATH)\n",
    "\n",
    "# cap = cv2.VideoCapture(0)q\n",
    "video_path = join('./','buf_data','520_TW_president_speech.mp4')\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "for i in range(random.randint(0,100)):\n",
    "    ret, frame = cap.read()\n",
    "print 'start'\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    faces = detect_face(frame, return_max_area_face=False)\n",
    "#     faces = detect_face(frame)\n",
    "#     frame = bounding_face(frame, faces, 2.)\n",
    "    frame = bounding_face_keep(frame, faces, 280)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('k'):\n",
    "        for i in range(random.randint(0,200)):\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print np.mean(buf), np.var(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-515107abbb09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_max_area_face\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_face_keep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-515107abbb09>\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(image, return_max_area_face)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_max_area_face\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from time import time\n",
    "from os.path import join\n",
    "    \n",
    "def detect_face(image, return_max_area_face=True):\n",
    "    if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = cv2.imdecode(image, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    # None is we don't found an image\n",
    "    if not len(faces) > 0:\n",
    "        return []\n",
    "    if return_max_area_face:\n",
    "        max_area_face = faces[0]\n",
    "        for face in faces:\n",
    "            if face[2] * face[3] > max_area_face[2] * max_area_face[3]:\n",
    "                max_area_face = face\n",
    "        faces = [max_area_face, ]\n",
    "\n",
    "    return faces\n",
    "def crop_face_keep(frame, faces, box_constraint):\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        offset_x = (box_constraint-w)/2.\n",
    "        offset_y = (box_constraint-h)/2.\n",
    "        rect = [x-offset_x, y-offset_y, box_constraint, box_constraint]\n",
    "        for i,a in enumerate(rect):\n",
    "            rect[i] = int(a)\n",
    "        rect = tuple(rect)\n",
    "\n",
    "        \n",
    "\n",
    "        x,y = rect[:2]\n",
    "        x2 = x + rect[2]\n",
    "        y2 = y + rect[3]\n",
    "    #         for 蔡英文\n",
    "        if x > 450 and x2 < 1000:\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x2), int(y2)), color=(255,255,255), thickness=5)\n",
    "            return True, frame[y:y2,x:x2,:]\n",
    "    return False, None\n",
    "\n",
    "\n",
    "    \n",
    "CASC_PATH = join('./','haarcascade_files','haarcascade_frontalface_default.xml')\n",
    "cascade_classifier = cv2.CascadeClassifier(CASC_PATH)\n",
    "\n",
    "# cap = cv2.VideoCapture(0)q\n",
    "video_path = join('./','buf_data','520_TW_president_speech.mp4')\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "idx = 0\n",
    "box = 280\n",
    "    \n",
    "path = join('./','buf_data','face')\n",
    "while(1):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    faces = detect_face(frame, return_max_area_face=False)\n",
    "    crop, face = crop_face_keep(frame, faces, box)\n",
    "    if crop:\n",
    "        out_path = join(path,'%d.jpg' % idx)\n",
    "        idx += 1\n",
    "        cv2.imwrite(out_path,face)\n",
    "        for i in range(10):\n",
    "            ret, frame = cap.read()\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print 'Done'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.15 (virtualenv)",
   "language": "python",
   "name": "python2.7.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
